{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1a4586-afaf-45cb-9d99-a61bdbbe1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "from PIL import Image\n",
    "\n",
    "# Setup logging for better tracking of progress\n",
    "\n",
    "logging.basicConfig(filename='logfile.log',level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9231c02-673d-40ce-b175-4232a14b4f60",
   "metadata": {},
   "source": [
    "\n",
    "### Data preprocessing and cleaning for json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc65126d-c062-4fb3-92ce-d17f83a1d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe(json_path):\n",
    "    \"\"\"Converts a JSON file to a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_json(json_path)\n",
    "        logging.info(f\"Successfully loaded data from {json_path}\")\n",
    "        return df\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error reading {json_path}: {e}\")\n",
    "        return pd.DataFrame()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04eb22d9-7ee1-4cbe-9b50-df97731d6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    \n",
    "    if df.empty:\n",
    "        logging.warning(\"DataFrame is empty. Skipping cleaning.\")\n",
    "        return df\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    for col in df.columns:\n",
    "        if 'date' in col.lower():\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    logging.info(\"Data cleaning completed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f709f1b-4659-4a48-86df-1c97a8ac84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned DataFrame as a CSV file\n",
    "def save_cleaned_data(df, output_path):\n",
    "    df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "# Function to store DataFrame in a database\n",
    "def store_in_database(df, table_name, database_url):\n",
    "    engine = create_engine(database_url)\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "    logging.info(f\"Data stored in the '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049d527-e4b9-4eb6-b25e-eceb12efb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_json_files(input_folder, output_folder, database_url=None):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Loop through each JSON file in the input folder\n",
    "    for json_file in os.listdir(input_folder):\n",
    "        if json_file.endswith('.json'):\n",
    "            input_path = os.path.join(input_folder, json_file)\n",
    "            logging.info(f\"Processing file: {input_path}\")\n",
    "            \n",
    "            # Convert JSON to DataFrame\n",
    "            df = json_to_dataframe(input_path)\n",
    "            \n",
    "            # Clean the DataFrame\n",
    "            cleaned_df = clean_dataframe(df)\n",
    "            \n",
    "            # Define output file path\n",
    "            output_file = os.path.join(output_folder, f\"cleaned_{json_file.replace('.json', '.csv')}\")\n",
    "            \n",
    "            # Save the cleaned data\n",
    "            save_cleaned_data(cleaned_df, output_file)\n",
    "            logging.info(f\"Saved cleaned data to: {output_file}\")\n",
    "            \n",
    "            # Optionally, store the cleaned data in a database\n",
    "            if database_url:\n",
    "                table_name = os.path.splitext(json_file)[0]  # Use the file name as the table name\n",
    "                store_in_database(cleaned_df, table_name, database_url)\n",
    "\n",
    "# Example usage\n",
    "input_folder = '../Data/scrapped_json_files'  \n",
    "output_folder = '../Data/cleaned_files' \n",
    "database_url = 'postgresql://postgres:newpassword@127.0.0.1:5432/warehouse' \n",
    "\n",
    "# Process all JSON files and optionally store in a database\n",
    "process_all_json_files(input_folder, output_folder, database_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0dc0d-4508-485f-8333-088fe6337626",
   "metadata": {},
   "source": [
    "### Image data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8478ff0-6150-4a3f-a33e-8f363e8d13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize images for object detection (YOLO)\n",
    "def resize_image(image_path, output_size=(512, 512)):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.resize(output_size)\n",
    "            img.save(image_path)  # Overwrite with resized image\n",
    "            logging.info(f\"Resized image: {image_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error resizing image {image_path}: {e}\")\n",
    "        try:\n",
    "            os.remove(image_path)  # Delete the image if resizing fails\n",
    "            logging.info(f\"Deleted non-resizable image: {image_path}\")\n",
    "        except Exception as delete_error:\n",
    "            logging.error(f\"Error deleting image {image_path}: {delete_error}\")\n",
    "\n",
    "# Apply the resize function to all images in the folder\n",
    "def transform_images(image_folder):\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        resize_image(image_path)\n",
    "\n",
    "# Transform all images in the 'images' directory\n",
    "transform_images('images/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
